{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8ceb3200",
   "metadata": {},
   "source": [
    "### Creat a Review-key mapping where a key is a unique id (asin_reviewerID) and value is a list  - [reviewtext, summary]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb10e159",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57ec157e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "review_df = pd.read_csv('../Project_Data/MiniReview.csv', index_col=0)\n",
    "metadata_df = pd.read_csv('../Project_Data/Metadata.csv', index_col=0)\n",
    "\n",
    "merged_df = review_df.merge(metadata_df[['category', 'description', 'title', 'feature', 'asin']], on='asin')\n",
    "merged_df.drop(['overall', 'vote', 'verified', 'reviewTime', 'reviewerName', 'unixReviewTime', 'image'], axis=1, inplace=True)\n",
    "merged_df.drop_duplicates(inplace=True)\n",
    "\n",
    "asin_reviews = {}\n",
    "for asin, reviews in tqdm(merged_df.groupby('asin')[['reviewerID', 'reviewText', 'summary']]):\n",
    "    review_list = []\n",
    "    for index, row in reviews.iterrows():\n",
    "        review_ID = row['reviewerID']\n",
    "        review_text = row['reviewText']\n",
    "        summary = row['summary']\n",
    "        review_list.append(f\"{review_ID} {review_text} {summary}\")\n",
    "    asin_reviews[asin] = review_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7e944cad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "98582it [00:05, 16439.71it/s]\n"
     ]
    }
   ],
   "source": [
    "review_key_mapping = {}\n",
    "for ind, row in tqdm(merged_df.iterrows()):\n",
    "    unique_id = row['asin'] + '_' + row['reviewerID']\n",
    "    review_key_mapping[unique_id] = [row['reviewText'], row['summary']]\n",
    "\n",
    "with open('../Output/Review_key_mapping.pickle', 'wb') as file:\n",
    "    pickle.dump(review_key_mapping, file, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dd0a544b",
   "metadata": {},
   "source": [
    "### Perform Sentiment Analysis for each aspect on the entire review dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a6dc72ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch.nn.functional as F\n",
    "from transformers import pipeline\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e2b65f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load Aspect-Based Sentiment Analysis model\n",
    "absa_tokenizer = AutoTokenizer.from_pretrained(\"yangheng/deberta-v3-base-absa-v1.1\")\n",
    "absa_model = AutoModelForSequenceClassification \\\n",
    "  .from_pretrained(\"yangheng/deberta-v3-base-absa-v1.1\").cuda()\n",
    "\n",
    "# Load a traditional Sentiment Analysis model\n",
    "sentiment_model_path = \"cardiffnlp/twitter-xlm-roberta-base-sentiment\"\n",
    "sentiment_model = pipeline(\"sentiment-analysis\", model=sentiment_model_path,\n",
    "                          tokenizer=sentiment_model_path)\n",
    "\n",
    "hardcoded_dict = {'quality' : {'quality', 'material', 'durable', 'high-quality', 'low-quality', 'light', 'thin', 'thick', 'soft', 'made', \n",
    "            'luxurious', 'luxury', 'fading', 'wrinkle', 'matte', 'High-quality','Well-made','Durable','Sturdy','Strong','Solid', 'construction','craftsmanship','detail', 'detailed', 'fine', 'Luxurious','Premium','Long-lasting','Robust','Substantial','Heavy-duty','Resilient','Dependable','Superior','Top-notch','Flimsy','Cheaply', 'made','make', 'Poor','Shoddy', 'weak', 'Unreliable','Inferior'},                    \n",
    "'price' : {'price', 'pricy', 'value', 'value-for-money', 'money', 'charge', 'charging', 'amount', 'payment',  \n",
    "           'rate', 'worth', 'total', 'sum', 'fare', 'expense', 'valuation', 'valuable',  'estimate', 'expense', \n",
    "           'expenses', 'expenditure', 'cost', 'costly', 'Affordable','Inexpensive','Budget-friendly','budget','deal','Reasonable','Cheap','Economical','Cost-effective','Expensive','Overpriced','Too pricey','Steep','Costly','Outrageous','Pricey','Investment piece','Bargain','Discounted','discount','sale','Clearance','Marked','fair' }, \n",
    "      \n",
    "'fit' : {'fit', 'fitting', 'size', 'oversize', 'oversized', 'tight', 'loose', 'small', 'big', 'medium', 'snug', \n",
    "         'stretch', 'stretchy', 'baggy', 'perfect', 'perfect-fit', 'supportive', 'support', 'supports', 'large', 'Cropped',\n",
    "'Long','Short','Petite','Regular','Tall','Wide','Narrow','Flattering','Unflattering','Bulky','Clingy','Flowy','Shapeless','Figure-hugging','Bodycon','Relaxed'}, \n",
    "'comfort' :\n",
    "{'comfort', 'cozy', 'comfortable', 'comforter', 'ease', 'comfortableness', 'comfortability', 'comfy',\n",
    "'Comfortable','Soft','Cozy','Breathable','Lightweight','Stretchy','Snug','Roomy','Supportive','Cushiony','Comfy','Relaxing','Easy to wear','Non-restrictive','Plush','Smooth','Well-fitting','Comfortable fit','Easy to move in','pinching','rubbing','chafing','digging','squeezing','tightness','slipping','discomfort','irritation','itching'} }\n",
    "\n",
    "aspect_dict = {}\n",
    "for aspect, keys in hardcoded_dict.items():\n",
    "    synonyms = [key.lower() for key in keys]\n",
    "    aspect_dict[aspect] = synonyms\n",
    "\n",
    "def aspect_based_sentiment_analysis_v1(asin):\n",
    "    \n",
    "    global aspect_dict, asin_reviews\n",
    "    aspect_words = aspect_dict\n",
    "    aspects = list(aspect_dict.keys())\n",
    "    # Get the first ASIN in the input dictionary\n",
    "    reviews_data = asin_reviews[asin]\n",
    "\n",
    "    # Perform aspect-based sentiment analysis for the chosen aspect and each sentence in the reviews\n",
    "    scores = []\n",
    "    for review in reviews_data:\n",
    "        review_id, review_text = review.split(\" \", 1)\n",
    "        review_scores = []\n",
    "        for aspect in aspects:\n",
    "            # TODO : Preprocess review text \n",
    "            if any(word in review_text.lower() for word in aspect_words[aspect]):\n",
    "                # Concatenate the input text with the aspect text and add special tokens\n",
    "                input_text = f\"[CLS] {review_text} [SEP] {aspect} [SEP]\"\n",
    "                # Tokenize the input text using the ABSA tokenizer\n",
    "                inputs = absa_tokenizer(input_text, return_tensors=\"pt\", padding=True, truncation=True).to(\"cuda\")\n",
    "                # Pass the input through the ABSA model to get the aspect-based sentiment probabilities\n",
    "                with torch.no_grad():\n",
    "                    outputs = absa_model(**inputs)\n",
    "                    probs = F.softmax(outputs.logits, dim=1)\n",
    "                    probs = probs.cpu().detach().numpy()[0]\n",
    "                    probs = [float(f\"{p:.5f}\") for p in probs]\n",
    "                review_scores.append((aspect, probs))\n",
    "            else:\n",
    "                review_scores.append((aspect, [0.0, 0.0, 0.0]))\n",
    "        scores.append((review_id, review_scores))\n",
    "\n",
    "    # Return the aspect-based sentiment scores\n",
    "    return {asin: scores}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ed0db86e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5543/5543 [1:17:57<00:00,  1.19it/s]\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for asin in tqdm(list(asin_reviews.keys())):\n",
    "    results.append(aspect_based_sentiment_analysis_v1(asin= asin))\n",
    "\n",
    "import pickle\n",
    "with open('../Output/Review_sentiments.picke', 'wb') as file:\n",
    "    pickle.dump(results, file, protocol = pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3b3d9a6d",
   "metadata": {},
   "source": [
    "### Make a dictionary to idetify for each produc the top 2 positive and negative review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "484f4a4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5543/5543 [00:00<00:00, 21047.98it/s]\n"
     ]
    }
   ],
   "source": [
    "top_review_dict = {}\n",
    "\n",
    "for result in tqdm(results):\n",
    "\n",
    "    asin = list(result.keys())[0]\n",
    "    reviews = list(result.values())[0]\n",
    "\n",
    "    aspect_dict = {'quality' : {'positive' : {'score_1' :0, 'item_1':None, 'score_2':0, 'item_2':None}, \n",
    "                            'negative' : {'score_1' :0, 'item_1':None, 'score_2':0, 'item_2':None}},\n",
    "               'price'  : {'positive' : {'score_1' :0, 'item_1':None, 'score_2':0, 'item_2':None}, \n",
    "                            'negative' : {'score_1' :0, 'item_1':None, 'score_2':0, 'item_2':None}},\n",
    "               'fit' :    {'positive' : {'score_1' :0, 'item_1':None, 'score_2':0, 'item_2':None}, \n",
    "                            'negative' : {'score_1' :0, 'item_1':None, 'score_2':0, 'item_2':None}},\n",
    "               'comfort' : {'positive' : {'score_1' :0, 'item_1':None, 'score_2':0, 'item_2':None}, \n",
    "                            'negative' : {'score_1' :0, 'item_1':None, 'score_2':0, 'item_2':None}}}\n",
    "    \n",
    "    for reviewer_id, aspect_details in reviews:\n",
    "        unique_id = asin+'_'+reviewer_id\n",
    "        for aspect,aspect_values in aspect_details:\n",
    "            if aspect_values[0]!=0:\n",
    "                # Negative sentiment\n",
    "                if aspect_values[0]>0.5:\n",
    "                    if aspect_dict[aspect]['negative']['score_1'] == 0:\n",
    "                        aspect_dict[aspect]['negative']['score_1'] = aspect_values[0]\n",
    "                        aspect_dict[aspect]['negative']['item_1'] = unique_id\n",
    "                    elif aspect_dict[aspect]['negative']['score_1'] < aspect_values[0]:\n",
    "                        aspect_dict[aspect]['negative']['score_2'] = aspect_dict[aspect]['negative']['score_1']\n",
    "                        aspect_dict[aspect]['negative']['item_2'] = aspect_dict[aspect]['negative']['item_1']\n",
    "                        aspect_dict[aspect]['negative']['score_1'] = aspect_values[0]\n",
    "                        aspect_dict[aspect]['negative']['item_1'] = unique_id\n",
    "                    elif aspect_dict[aspect]['negative']['score_1'] > aspect_values[0]:\n",
    "                        if aspect_dict[aspect]['negative']['score_2'] < aspect_values[0]:\n",
    "                            aspect_dict[aspect]['negative']['score_2'] = aspect_values[0]\n",
    "                            aspect_dict[aspect]['negative']['item_2'] = unique_id\n",
    "                # Positive sentiment\n",
    "                elif aspect_values[2]>0.5:\n",
    "                    if aspect_dict[aspect]['positive']['score_1'] == 0:\n",
    "                        aspect_dict[aspect]['positive']['score_1'] = aspect_values[2]\n",
    "                        aspect_dict[aspect]['positive']['item_1'] = unique_id\n",
    "                    elif aspect_dict[aspect]['positive']['score_1'] < aspect_values[2]:\n",
    "                        aspect_dict[aspect]['positive']['score_2'] = aspect_dict[aspect]['positive']['score_1']\n",
    "                        aspect_dict[aspect]['positive']['item_2'] = aspect_dict[aspect]['positive']['item_1']\n",
    "                        aspect_dict[aspect]['positive']['score_1'] = aspect_values[2]\n",
    "                        aspect_dict[aspect]['positive']['item_1'] = unique_id\n",
    "                    elif aspect_dict[aspect]['positive']['score_1'] > aspect_values[2]:\n",
    "                        if aspect_dict[aspect]['positive']['score_2'] < aspect_values[2]:\n",
    "                            aspect_dict[aspect]['positive']['score_2'] = aspect_values[2]\n",
    "                            aspect_dict[aspect]['positive']['item_2'] = unique_id\n",
    "    \n",
    "    top_review_dict[asin] = aspect_dict\n",
    "\n",
    "with open('../Output/Top_reviews.pickle', 'wb') as file:\n",
    "    pickle.dump(top_review_dict, file, protocol=pickle.HIGHEST_PROTOCOL) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1a6636b4",
   "metadata": {},
   "source": [
    "### Create Review dict for Ease of Reading files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "106023e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_dict_for_Swati = {}\n",
    "\n",
    "# def get_data_from_review_key_mapping(unique_id):\n",
    "\n",
    "#     if review_key_mapping[unique_id] \n",
    "\n",
    "for asin, aspect_dict in top_review_dict.items():\n",
    "\n",
    "    # Quality\n",
    "    list_of_reviews = []\n",
    "    if aspect_dict['quality']['positive']['item_1'] is None:\n",
    "        list_of_reviews.append('')\n",
    "    else:\n",
    "        list_of_reviews.append(review_key_mapping[aspect_dict['quality']['positive']['item_1']])\n",
    "\n",
    "    if aspect_dict['quality']['positive']['item_2'] is None:\n",
    "        list_of_reviews.append('')\n",
    "    else:\n",
    "        list_of_reviews.append(review_key_mapping[aspect_dict['quality']['positive']['item_2']])\n",
    "\n",
    "    if aspect_dict['quality']['negative']['item_1'] is None:\n",
    "        list_of_reviews.append('')\n",
    "    else:\n",
    "        list_of_reviews.append(review_key_mapping[aspect_dict['quality']['negative']['item_1']])\n",
    "\n",
    "    if aspect_dict['quality']['negative']['item_2'] is None:\n",
    "        list_of_reviews.append('')\n",
    "    else:\n",
    "        list_of_reviews.append(review_key_mapping[aspect_dict['quality']['negative']['item_2']])\n",
    "\n",
    "    # comfort\n",
    "    if aspect_dict['comfort']['positive']['item_1'] is None:\n",
    "        list_of_reviews.append('')\n",
    "    else:\n",
    "        list_of_reviews.append(review_key_mapping[aspect_dict['comfort']['positive']['item_1']])\n",
    "\n",
    "    if aspect_dict['comfort']['positive']['item_2'] is None:\n",
    "        list_of_reviews.append('')\n",
    "    else:\n",
    "        list_of_reviews.append(review_key_mapping[aspect_dict['comfort']['positive']['item_2']])\n",
    "\n",
    "    if aspect_dict['comfort']['negative']['item_1'] is None:\n",
    "        list_of_reviews.append('')\n",
    "    else:\n",
    "        list_of_reviews.append(review_key_mapping[aspect_dict['comfort']['negative']['item_1']])\n",
    "\n",
    "    if aspect_dict['comfort']['negative']['item_2'] is None:\n",
    "        list_of_reviews.append('')\n",
    "    else:\n",
    "        list_of_reviews.append(review_key_mapping[aspect_dict['comfort']['negative']['item_2']])\n",
    "\n",
    "    # price\n",
    "    if aspect_dict['price']['positive']['item_1'] is None:\n",
    "        list_of_reviews.append('')\n",
    "    else:\n",
    "        list_of_reviews.append(review_key_mapping[aspect_dict['price']['positive']['item_1']])\n",
    "\n",
    "    if aspect_dict['price']['positive']['item_2'] is None:\n",
    "        list_of_reviews.append('')\n",
    "    else:\n",
    "        list_of_reviews.append(review_key_mapping[aspect_dict['price']['positive']['item_2']])\n",
    "\n",
    "    if aspect_dict['price']['negative']['item_1'] is None:\n",
    "        list_of_reviews.append('')\n",
    "    else:\n",
    "        list_of_reviews.append(review_key_mapping[aspect_dict['price']['negative']['item_1']])\n",
    "\n",
    "    if aspect_dict['price']['negative']['item_2'] is None:\n",
    "        list_of_reviews.append('')\n",
    "    else:\n",
    "        list_of_reviews.append(review_key_mapping[aspect_dict['price']['negative']['item_2']])\n",
    "\n",
    "    # fit\n",
    "    if aspect_dict['fit']['positive']['item_1'] is None:\n",
    "        list_of_reviews.append('')\n",
    "    else:\n",
    "        list_of_reviews.append(review_key_mapping[aspect_dict['fit']['positive']['item_1']])\n",
    "\n",
    "    if aspect_dict['fit']['positive']['item_2'] is None:\n",
    "        list_of_reviews.append('')\n",
    "    else:\n",
    "        list_of_reviews.append(review_key_mapping[aspect_dict['fit']['positive']['item_2']])\n",
    "\n",
    "    if aspect_dict['fit']['negative']['item_1'] is None:\n",
    "        list_of_reviews.append('')\n",
    "    else:\n",
    "        list_of_reviews.append(review_key_mapping[aspect_dict['fit']['negative']['item_1']])\n",
    "\n",
    "    if aspect_dict['fit']['negative']['item_2'] is None:\n",
    "        list_of_reviews.append('')\n",
    "    else:\n",
    "        list_of_reviews.append(review_key_mapping[aspect_dict['fit']['negative']['item_2']])\n",
    "\n",
    "\n",
    "    review_dict_for_Swati[asin] = list_of_reviews\n",
    "\n",
    "with open('../Output/Review_dict_for_Swati.pickle', 'wb') as file:\n",
    "    pickle.dump(review_dict_for_Swati, file, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
